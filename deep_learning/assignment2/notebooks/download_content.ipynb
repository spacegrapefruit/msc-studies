{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5dd8201",
   "metadata": {},
   "source": [
    "# Downloading Wikipedia Articles for Indexing\n",
    "\n",
    "This notebook downloads ~5,000 Wikipedia articles programmatically using the `wikipedia` library, and saves the results for subsequent indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8ca412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set language to English\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "# directory to save articles\n",
    "OUTPUT_DIR = \"../data/input\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513629ab",
   "metadata": {},
   "source": [
    "## Step 1: Collect article titles via two-letter prefixes\n",
    "\n",
    "We generate all two-letter combinations (`aa`, `ab`, ..., `zz`) to search Wikipedia. For each prefix, we retrieve up to 10 article titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9303f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def list_prefix(prefix: str, results: int = 10) -> list:\n",
    "    time.sleep(0.1)  # avoid throttling\n",
    "    titles = wikipedia.search(prefix, results=results)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b960a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two-letter prefixes (aa, ab, ..., zz)\n",
    "letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "prefixes = (\"\".join(p) for p in itertools.product(letters, repeat=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 676/676 [02:35<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "collected_titles = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = []\n",
    "    for prefix in prefixes:\n",
    "        future = executor.submit(list_prefix, prefix)\n",
    "        futures.append(future)\n",
    "\n",
    "    for future in tqdm(futures):\n",
    "        try:\n",
    "            results = future.result()\n",
    "            collected_titles.extend(results)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing future: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6afa63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "collected_titles = sorted(set(collected_titles))\n",
    "\n",
    "len(collected_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d933d7",
   "metadata": {},
   "source": [
    "## Step 2: Download Each Article's Content\n",
    "\n",
    "Using the list of unique titles, we fetch page details for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfcaec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def cached_get_page(title: str) -> str:\n",
    "    time.sleep(0.1)\n",
    "    page = wikipedia.page(title)\n",
    "    # print(f\"Fetched page: {title}\")\n",
    "\n",
    "    return {\n",
    "        \"title\": page.title,\n",
    "        \"content\": page.content,\n",
    "        \"url\": page.url,\n",
    "        \"summary\": page.summary,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0a28e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4867/6581 [04:56<01:15, 22.72it/s]ERROR:root:Error processing future: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?prop=revisions&rvprop=content&rvparse=&rvlimit=1&titles=Rx+%28disambiguation%29&format=json&action=query (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd90ecf1f10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      " 89%|████████▉ | 5876/6581 [05:47<00:36, 19.06it/s]ERROR:root:Error processing future: HTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=volkswagen+r&format=json&action=query (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd90f310590>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "100%|██████████| 6581/6581 [06:33<00:00, 16.74it/s]\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = []\n",
    "    for title in collected_titles:\n",
    "        future = executor.submit(cached_get_page, title)\n",
    "        futures.append(future)\n",
    "\n",
    "    for future in tqdm(futures):\n",
    "        try:\n",
    "            page_item = future.result()\n",
    "            articles.append(page_item)\n",
    "        except wikipedia.exceptions.DisambiguationError as e:\n",
    "            # logging.warning(f\"Disambiguation error for {e.title}: {e.options}\")\n",
    "            pass\n",
    "        except wikipedia.exceptions.PageError as e:\n",
    "            # logging.error(f\"Page error: {e}\")\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing future: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bd23c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4573"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebf5f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "912b05f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>AAI RQ-2 Pioneer</td>\n",
       "      <td>The AAI RQ-2 Pioneer is an unmanned aerial veh...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/AAI_RQ-2_Pioneer</td>\n",
       "      <td>The AAI RQ-2 Pioneer is an unmanned aerial veh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>News</td>\n",
       "      <td>News is information about current events. This...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News</td>\n",
       "      <td>News is information about current events. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>H. L. Green Company</td>\n",
       "      <td>H. L. Green was a five and dime store chain in...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/H._L._Green_Company</td>\n",
       "      <td>H. L. Green was a five and dime store chain in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>A</td>\n",
       "      <td>A, or a, is the first letter and the first vow...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A</td>\n",
       "      <td>A, or a, is the first letter and the first vow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>JK Place</td>\n",
       "      <td>J.K.Place is a chain of Italian boutique hotel...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/JK_Place</td>\n",
       "      <td>J.K.Place is a chain of Italian boutique hotel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                            content  \\\n",
       "151      AAI RQ-2 Pioneer  The AAI RQ-2 Pioneer is an unmanned aerial veh...   \n",
       "2717                 News  News is information about current events. This...   \n",
       "1451  H. L. Green Company  H. L. Green was a five and dime store chain in...   \n",
       "153                     A  A, or a, is the first letter and the first vow...   \n",
       "1814             JK Place  J.K.Place is a chain of Italian boutique hotel...   \n",
       "\n",
       "                                                    url  \\\n",
       "151      https://en.wikipedia.org/wiki/AAI_RQ-2_Pioneer   \n",
       "2717                 https://en.wikipedia.org/wiki/News   \n",
       "1451  https://en.wikipedia.org/wiki/H._L._Green_Company   \n",
       "153                     https://en.wikipedia.org/wiki/A   \n",
       "1814             https://en.wikipedia.org/wiki/JK_Place   \n",
       "\n",
       "                                                summary  \n",
       "151   The AAI RQ-2 Pioneer is an unmanned aerial veh...  \n",
       "2717  News is information about current events. This...  \n",
       "1451  H. L. Green was a five and dime store chain in...  \n",
       "153   A, or a, is the first letter and the first vow...  \n",
       "1814  J.K.Place is a chain of Italian boutique hotel...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a4827",
   "metadata": {},
   "source": [
    "## Step 3: Saving the articles\n",
    "\n",
    "We save the DataFrame for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9672f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.to_parquet(\n",
    "    os.path.join(OUTPUT_DIR, \"wikipedia_articles.parquet\"),\n",
    "    index=False,\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2-RpA_TLD6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
